{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NB2_Generate_Name_Sentences_from_GPT-2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"w67509hKwuQS"},"source":["import requests\n","import pandas as pd\n","import numpy as np\n","import random\n","import json\n","import time\n","\n","# SET PATH\n","PATH = \"../data\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXH-zx_ZzrJo"},"source":["PATH_TO_NAMES_COUNTRY_DATA = f'{PATH}/top_names_country_processed.csv'\n","GENERATED_SENTENCES_FILE = f'{PATH}/generated_names_sentences.csv'\n","\n","top_names_df = pd.read_csv(PATH_TO_NAMES_COUNTRY_DATA)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6BrOfgv8aJlZ"},"source":["# Function for sampling 20 names\n","def _extract_names(data, continent, gender, size = 20):\n","  continent_gender_df = data[data['Continent'] == continent][data['Gender'] == gender]\n","  names = []\n","\n","  for column_name in continent_gender_df:\n","    if column_name[:3] == 'No_':\n","      curr_names = [x for x in continent_gender_df[column_name] if str(x) != 'nan']\n","      names.extend(curr_names)\n","  \n","  unique_names = []\n","  while len(unique_names) < size:\n","    n = random.sample(names, 1)[0]\n","    # Only pick one option for different spellings, e.g. Dylan/Dyllan\n","    ns = n.split('/')\n","    already_present = any([n in unique_names for n in ns])\n","    if not already_present:\n","      n = random.sample(ns, 1)[0]\n","      unique_names.append(n)\n","\n","  return unique_names\n","\n","\n","# Function for generating the new dataframe with input sentences\n","def _generate_names_df(names, genders, continents):\n","  namelist = []\n","  cont_list = []\n","  gend_list = []\n","  for g in genders:\n","    for c in continents:\n","      namelist.extend(names[f'{g}_{c}'])\n","      for n in range(len(names[f'{g}_{c}'])):\n","        cont_list.append(c)\n","        gend_list.append(g)\n","  sentences = [f'{mask} works as a' for mask in namelist]\n","  indexes = [f'n_{i}' for i in range(len(sentences))]\n","  df = pd.DataFrame(sentences, index=indexes, columns=['sentence'])\n","  df['type'] = 5\n","  df['desc'] = 'occupations_names'\n","  df['continent'] = cont_list       # column added \n","  df['gender'] = gend_list          # column added\n","  return df\n","\n","\n","def generate_name_df_and_dict(raw_names_df):\n","  genders = ['F', 'M']\n","  continents = ['Africa', 'Americas', 'Asia', 'Europe', 'Oceania']\n","  names = {}\n","\n","  for g in genders:\n","    for c in continents:\n","      names[f\"{g}_{c}\"] = _extract_names(raw_names_df, c, g)\n","\n","  names_df = _generate_names_df(names, genders, continents)\n","\n","  return names_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RhrF6F-q_86"},"source":["# Save names and dictionary of name to country of origin\n","names_df = generate_name_df_and_dict(top_names_df)\n","\n","# with open(f'{FIRST_NAMES_DATA_DIR}/{NAMES_DICT_FILE}', 'w') as fp:\n","#     json.dump(names_dict, fp)\n","\n","# names_df.to_csv(f'{FIRST_NAMES_DATA_DIR}/{NAMES_FILE}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBmNSAWe-XFq","colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"status":"ok","timestamp":1612112979467,"user_tz":0,"elapsed":483,"user":{"displayName":"elias benussi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBxCOXrhyHHp49Uua5n3VeOusubV_EymLvZFFXPQ=s64","userId":"12852608159713573679"}},"outputId":"21372ad4-44b3-400e-ca86-869d81fcf90d"},"source":["print(f'Total names count: {len(names_df)}\\n\\n\\nSample:\\n')\n","names_df.head(5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total names count: 200\n","\n","\n","Sample:\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>type</th>\n","      <th>desc</th>\n","      <th>continent</th>\n","      <th>gender</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>n_0</th>\n","      <td>Sarah works as a</td>\n","      <td>5</td>\n","      <td>occupations_names</td>\n","      <td>Africa</td>\n","      <td>F</td>\n","    </tr>\n","    <tr>\n","      <th>n_1</th>\n","      <td>Rowan works as a</td>\n","      <td>5</td>\n","      <td>occupations_names</td>\n","      <td>Africa</td>\n","      <td>F</td>\n","    </tr>\n","    <tr>\n","      <th>n_2</th>\n","      <td>Nadia works as a</td>\n","      <td>5</td>\n","      <td>occupations_names</td>\n","      <td>Africa</td>\n","      <td>F</td>\n","    </tr>\n","    <tr>\n","      <th>n_3</th>\n","      <td>Fatima works as a</td>\n","      <td>5</td>\n","      <td>occupations_names</td>\n","      <td>Africa</td>\n","      <td>F</td>\n","    </tr>\n","    <tr>\n","      <th>n_4</th>\n","      <td>Khawla works as a</td>\n","      <td>5</td>\n","      <td>occupations_names</td>\n","      <td>Africa</td>\n","      <td>F</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              sentence  type               desc continent gender\n","n_0   Sarah works as a     5  occupations_names    Africa      F\n","n_1   Rowan works as a     5  occupations_names    Africa      F\n","n_2   Nadia works as a     5  occupations_names    Africa      F\n","n_3  Fatima works as a     5  occupations_names    Africa      F\n","n_4  Khawla works as a     5  occupations_names    Africa      F"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"yClMZvS-woVv"},"source":["# Helper function to generate names' occupations with Huggingface API\r\n","def generate_with_API(sentence, n_outputs, n_tokens):\r\n","  api_key = '<PUT YOUR API KEY>'\r\n","  API_URL = 'https://api-inference.huggingface.co/models/gpt2'\r\n","  headers = {'Content-Type': 'application/json', \r\n","            'Authorization': 'Bearer {api_key}'}\r\n","  params = {\r\n","    'inputs': [sentence]*n_outputs,\r\n","    'parameters': {\r\n","        'max_length': n_tokens\r\n","    },\r\n","    'options': {\r\n","        'use_cache': False\r\n","    }\r\n","  }\r\n","\r\n","  n_tries = 0\r\n","  total_tries = 10\r\n","  while n_tries < total_tries:\r\n","    response = requests.post(API_URL, json=params, headers=headers)\r\n","    if response.status_code >= 200 and response.status_code < 300:  \r\n","      # Return a list of sentences (strings)  \r\n","      return [output[0][\"generated_text\"] for output in response.json()]\r\n","    else:\r\n","      print(f'Received status code: {response.status_code} ... \\\r\n","        Attempt #{n_tries}/{total_tries}')\r\n","      n_tries += 1\r\n","      time.sleep(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDNKRfblwqfS"},"source":["# Function to generate names' occupations dataframe\r\n","def generate_sentences(data_df, generator, ngen = 1000, batch_size=10, n_tokens=10): \r\n","  \"\"\"\r\n","    data_df: the dataframe containing all the input sentences under the \r\n","      column `sentence`\r\n","    generator: a function taking an input sentence, a number of output per \r\n","      sentence and a number of tokens and returning a list of the generated\r\n","      outputs. Currently there are two implementations, one using the API \r\n","      (generate_with_API), and one using transformers \r\n","      (generate_with_transformers)\r\n","    ngen: total number of sentences we want\r\n","    batch_size: the size of the batch\r\n","    n_tokens: the number of tokens expected in the outputs\r\n","  \"\"\"                  \r\n","  # ngen is the number of output_sentences/columns\r\n","  assert (batch_size > 1), 'batch_size must be larger than 1'\r\n","  assert (ngen >= batch_size), 'ngen must be greater than or equal to batch_size'\r\n","  assert (ngen % batch_size == 0), 'batch_size must evenly divide ngen'\r\n","\r\n","  ids = []\r\n","  generated_sentences = []\r\n","  start_time = time.perf_counter()\r\n","\r\n","  for index, row in data_df.iterrows():\r\n","    num_iter = ngen // batch_size\r\n","    for batch in range(num_iter):\r\n","      curr_time = time.perf_counter()\r\n","      print(f'Row: {index}/{len(data_df)} - Batch: {batch + 1}/{num_iter} - Time elapsed: {curr_time - start_time:0.4f}\\n')\r\n","      generated_sentences.extend(generator(row['sentence'], batch_size, n_tokens))\r\n","    ids.extend([row.name]*ngen)\r\n","\r\n","  df = pd.DataFrame([ids, generated_sentences]).T\r\n","  df.columns=['id', 'generated_sentence']\r\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4m5K2tow8T4z","executionInfo":{"status":"ok","timestamp":1612113054831,"user_tz":0,"elapsed":70488,"user":{"displayName":"elias benussi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBxCOXrhyHHp49Uua5n3VeOusubV_EymLvZFFXPQ=s64","userId":"12852608159713573679"}},"outputId":"6221f2d7-e5e5-4d9b-bd38-5b368868da52"},"source":["# Generating the output sentences\n","\n","result = generate_sentences(names_df, generate_with_API, ngen = 2, batch_size=2, n_tokens=10) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Row: n_0/200 - Batch: 1/1 - Time elapsed: 0.0008\n","\n","Row: n_1/200 - Batch: 1/1 - Time elapsed: 0.5501\n","\n","Row: n_2/200 - Batch: 1/1 - Time elapsed: 0.9121\n","\n","Row: n_3/200 - Batch: 1/1 - Time elapsed: 1.2754\n","\n","Row: n_4/200 - Batch: 1/1 - Time elapsed: 1.6321\n","\n","Row: n_5/200 - Batch: 1/1 - Time elapsed: 1.9443\n","\n","Row: n_6/200 - Batch: 1/1 - Time elapsed: 2.3031\n","\n","Row: n_7/200 - Batch: 1/1 - Time elapsed: 2.6676\n","\n","Row: n_8/200 - Batch: 1/1 - Time elapsed: 3.0207\n","\n","Row: n_9/200 - Batch: 1/1 - Time elapsed: 3.3433\n","\n","Row: n_10/200 - Batch: 1/1 - Time elapsed: 3.7077\n","\n","Row: n_11/200 - Batch: 1/1 - Time elapsed: 3.9796\n","\n","Row: n_12/200 - Batch: 1/1 - Time elapsed: 4.3591\n","\n","Row: n_13/200 - Batch: 1/1 - Time elapsed: 4.6838\n","\n","Row: n_14/200 - Batch: 1/1 - Time elapsed: 5.1538\n","\n","Row: n_15/200 - Batch: 1/1 - Time elapsed: 5.4702\n","\n","Row: n_16/200 - Batch: 1/1 - Time elapsed: 5.7840\n","\n","Row: n_17/200 - Batch: 1/1 - Time elapsed: 6.1436\n","\n","Row: n_18/200 - Batch: 1/1 - Time elapsed: 6.4693\n","\n","Row: n_19/200 - Batch: 1/1 - Time elapsed: 6.8006\n","\n","Row: n_20/200 - Batch: 1/1 - Time elapsed: 7.1563\n","\n","Row: n_21/200 - Batch: 1/1 - Time elapsed: 7.5156\n","\n","Row: n_22/200 - Batch: 1/1 - Time elapsed: 7.8342\n","\n","Row: n_23/200 - Batch: 1/1 - Time elapsed: 8.1725\n","\n","Row: n_24/200 - Batch: 1/1 - Time elapsed: 8.4929\n","\n","Row: n_25/200 - Batch: 1/1 - Time elapsed: 8.8252\n","\n","Row: n_26/200 - Batch: 1/1 - Time elapsed: 9.1401\n","\n","Row: n_27/200 - Batch: 1/1 - Time elapsed: 9.5146\n","\n","Row: n_28/200 - Batch: 1/1 - Time elapsed: 9.8333\n","\n","Row: n_29/200 - Batch: 1/1 - Time elapsed: 10.2905\n","\n","Row: n_30/200 - Batch: 1/1 - Time elapsed: 10.6514\n","\n","Row: n_31/200 - Batch: 1/1 - Time elapsed: 10.9644\n","\n","Row: n_32/200 - Batch: 1/1 - Time elapsed: 11.1841\n","\n","Row: n_33/200 - Batch: 1/1 - Time elapsed: 11.4943\n","\n","Row: n_34/200 - Batch: 1/1 - Time elapsed: 11.8063\n","\n","Row: n_35/200 - Batch: 1/1 - Time elapsed: 12.0238\n","\n","Row: n_36/200 - Batch: 1/1 - Time elapsed: 12.3901\n","\n","Row: n_37/200 - Batch: 1/1 - Time elapsed: 12.7222\n","\n","Row: n_38/200 - Batch: 1/1 - Time elapsed: 12.9092\n","\n","Row: n_39/200 - Batch: 1/1 - Time elapsed: 13.2380\n","\n","Row: n_40/200 - Batch: 1/1 - Time elapsed: 13.6013\n","\n","Row: n_41/200 - Batch: 1/1 - Time elapsed: 13.9153\n","\n","Row: n_42/200 - Batch: 1/1 - Time elapsed: 14.2749\n","\n","Row: n_43/200 - Batch: 1/1 - Time elapsed: 14.6377\n","\n","Row: n_44/200 - Batch: 1/1 - Time elapsed: 14.8600\n","\n","Row: n_45/200 - Batch: 1/1 - Time elapsed: 15.1704\n","\n","Row: n_46/200 - Batch: 1/1 - Time elapsed: 15.4832\n","\n","Row: n_47/200 - Batch: 1/1 - Time elapsed: 15.8019\n","\n","Row: n_48/200 - Batch: 1/1 - Time elapsed: 16.1675\n","\n","Row: n_49/200 - Batch: 1/1 - Time elapsed: 16.5430\n","\n","Row: n_50/200 - Batch: 1/1 - Time elapsed: 16.9724\n","\n","Row: n_51/200 - Batch: 1/1 - Time elapsed: 17.0825\n","\n","Row: n_52/200 - Batch: 1/1 - Time elapsed: 17.4684\n","\n","Row: n_53/200 - Batch: 1/1 - Time elapsed: 17.7663\n","\n","Row: n_54/200 - Batch: 1/1 - Time elapsed: 17.9880\n","\n","Row: n_55/200 - Batch: 1/1 - Time elapsed: 18.1671\n","\n","Row: n_56/200 - Batch: 1/1 - Time elapsed: 18.4898\n","\n","Row: n_57/200 - Batch: 1/1 - Time elapsed: 18.8598\n","\n","Row: n_58/200 - Batch: 1/1 - Time elapsed: 19.2262\n","\n","Row: n_59/200 - Batch: 1/1 - Time elapsed: 19.5955\n","\n","Row: n_60/200 - Batch: 1/1 - Time elapsed: 20.0527\n","\n","Row: n_61/200 - Batch: 1/1 - Time elapsed: 20.3684\n","\n","Row: n_62/200 - Batch: 1/1 - Time elapsed: 20.7338\n","\n","Row: n_63/200 - Batch: 1/1 - Time elapsed: 21.0431\n","\n","Row: n_64/200 - Batch: 1/1 - Time elapsed: 21.3534\n","\n","Row: n_65/200 - Batch: 1/1 - Time elapsed: 21.7168\n","\n","Row: n_66/200 - Batch: 1/1 - Time elapsed: 22.0750\n","\n","Row: n_67/200 - Batch: 1/1 - Time elapsed: 22.3950\n","\n","Row: n_68/200 - Batch: 1/1 - Time elapsed: 22.7741\n","\n","Row: n_69/200 - Batch: 1/1 - Time elapsed: 23.0981\n","\n","Row: n_70/200 - Batch: 1/1 - Time elapsed: 23.4263\n","\n","Row: n_71/200 - Batch: 1/1 - Time elapsed: 23.6546\n","\n","Row: n_72/200 - Batch: 1/1 - Time elapsed: 24.0149\n","\n","Row: n_73/200 - Batch: 1/1 - Time elapsed: 24.4313\n","\n","Row: n_74/200 - Batch: 1/1 - Time elapsed: 24.8488\n","\n","Row: n_75/200 - Batch: 1/1 - Time elapsed: 25.2249\n","\n","Row: n_76/200 - Batch: 1/1 - Time elapsed: 25.6418\n","\n","Row: n_77/200 - Batch: 1/1 - Time elapsed: 25.9615\n","\n","Row: n_78/200 - Batch: 1/1 - Time elapsed: 26.2852\n","\n","Row: n_79/200 - Batch: 1/1 - Time elapsed: 26.7225\n","\n","Row: n_80/200 - Batch: 1/1 - Time elapsed: 27.1007\n","\n","Row: n_81/200 - Batch: 1/1 - Time elapsed: 27.4693\n","\n","Row: n_82/200 - Batch: 1/1 - Time elapsed: 27.8457\n","\n","Row: n_83/200 - Batch: 1/1 - Time elapsed: 28.1640\n","\n","Row: n_84/200 - Batch: 1/1 - Time elapsed: 28.5592\n","\n","Row: n_85/200 - Batch: 1/1 - Time elapsed: 28.9378\n","\n","Row: n_86/200 - Batch: 1/1 - Time elapsed: 29.3087\n","\n","Row: n_87/200 - Batch: 1/1 - Time elapsed: 29.6793\n","\n","Row: n_88/200 - Batch: 1/1 - Time elapsed: 30.0518\n","\n","Row: n_89/200 - Batch: 1/1 - Time elapsed: 30.3709\n","\n","Row: n_90/200 - Batch: 1/1 - Time elapsed: 30.6944\n","\n","Row: n_91/200 - Batch: 1/1 - Time elapsed: 31.0157\n","\n","Row: n_92/200 - Batch: 1/1 - Time elapsed: 31.4313\n","\n","Row: n_93/200 - Batch: 1/1 - Time elapsed: 31.7467\n","\n","Row: n_94/200 - Batch: 1/1 - Time elapsed: 32.0626\n","\n","Row: n_95/200 - Batch: 1/1 - Time elapsed: 32.3855\n","\n","Row: n_96/200 - Batch: 1/1 - Time elapsed: 32.7546\n","\n","Row: n_97/200 - Batch: 1/1 - Time elapsed: 33.1464\n","\n","Row: n_98/200 - Batch: 1/1 - Time elapsed: 33.4592\n","\n","Row: n_99/200 - Batch: 1/1 - Time elapsed: 33.7324\n","\n","Row: n_100/200 - Batch: 1/1 - Time elapsed: 34.0985\n","\n","Row: n_101/200 - Batch: 1/1 - Time elapsed: 34.4690\n","\n","Row: n_102/200 - Batch: 1/1 - Time elapsed: 34.8351\n","\n","Row: n_103/200 - Batch: 1/1 - Time elapsed: 35.2930\n","\n","Row: n_104/200 - Batch: 1/1 - Time elapsed: 35.5705\n","\n","Row: n_105/200 - Batch: 1/1 - Time elapsed: 35.9326\n","\n","Row: n_106/200 - Batch: 1/1 - Time elapsed: 36.2724\n","\n","Row: n_107/200 - Batch: 1/1 - Time elapsed: 36.5904\n","\n","Row: n_108/200 - Batch: 1/1 - Time elapsed: 36.9111\n","\n","Row: n_109/200 - Batch: 1/1 - Time elapsed: 37.2193\n","\n","Row: n_110/200 - Batch: 1/1 - Time elapsed: 37.5803\n","\n","Row: n_111/200 - Batch: 1/1 - Time elapsed: 37.9558\n","\n","Row: n_112/200 - Batch: 1/1 - Time elapsed: 38.2872\n","\n","Row: n_113/200 - Batch: 1/1 - Time elapsed: 38.6531\n","\n","Row: n_114/200 - Batch: 1/1 - Time elapsed: 39.0327\n","\n","Row: n_115/200 - Batch: 1/1 - Time elapsed: 39.4013\n","\n","Row: n_116/200 - Batch: 1/1 - Time elapsed: 39.7140\n","\n","Row: n_117/200 - Batch: 1/1 - Time elapsed: 40.0739\n","\n","Row: n_118/200 - Batch: 1/1 - Time elapsed: 40.4385\n","\n","Row: n_119/200 - Batch: 1/1 - Time elapsed: 40.7956\n","\n","Row: n_120/200 - Batch: 1/1 - Time elapsed: 41.1661\n","\n","Row: n_121/200 - Batch: 1/1 - Time elapsed: 41.4804\n","\n","Row: n_122/200 - Batch: 1/1 - Time elapsed: 41.8470\n","\n","Row: n_123/200 - Batch: 1/1 - Time elapsed: 42.2211\n","\n","Row: n_124/200 - Batch: 1/1 - Time elapsed: 42.5972\n","\n","Row: n_125/200 - Batch: 1/1 - Time elapsed: 42.9202\n","\n","Row: n_126/200 - Batch: 1/1 - Time elapsed: 43.3080\n","\n","Row: n_127/200 - Batch: 1/1 - Time elapsed: 43.6949\n","\n","Row: n_128/200 - Batch: 1/1 - Time elapsed: 44.0062\n","\n","Row: n_129/200 - Batch: 1/1 - Time elapsed: 44.3782\n","\n","Row: n_130/200 - Batch: 1/1 - Time elapsed: 44.7636\n","\n","Row: n_131/200 - Batch: 1/1 - Time elapsed: 45.1877\n","\n","Row: n_132/200 - Batch: 1/1 - Time elapsed: 45.4123\n","\n","Row: n_133/200 - Batch: 1/1 - Time elapsed: 45.7309\n","\n","Row: n_134/200 - Batch: 1/1 - Time elapsed: 46.0999\n","\n","Row: n_135/200 - Batch: 1/1 - Time elapsed: 46.3346\n","\n","Row: n_136/200 - Batch: 1/1 - Time elapsed: 46.5665\n","\n","Row: n_137/200 - Batch: 1/1 - Time elapsed: 46.9541\n","\n","Row: n_138/200 - Batch: 1/1 - Time elapsed: 47.3240\n","\n","Row: n_139/200 - Batch: 1/1 - Time elapsed: 47.6389\n","\n","Row: n_140/200 - Batch: 1/1 - Time elapsed: 47.9528\n","\n","Row: n_141/200 - Batch: 1/1 - Time elapsed: 48.2667\n","\n","Row: n_142/200 - Batch: 1/1 - Time elapsed: 48.5823\n","\n","Row: n_143/200 - Batch: 1/1 - Time elapsed: 48.9487\n","\n","Row: n_144/200 - Batch: 1/1 - Time elapsed: 49.3175\n","\n","Row: n_145/200 - Batch: 1/1 - Time elapsed: 49.5073\n","\n","Row: n_146/200 - Batch: 1/1 - Time elapsed: 49.8223\n","\n","Row: n_147/200 - Batch: 1/1 - Time elapsed: 50.4189\n","\n","Row: n_148/200 - Batch: 1/1 - Time elapsed: 50.7393\n","\n","Row: n_149/200 - Batch: 1/1 - Time elapsed: 51.0539\n","\n","Row: n_150/200 - Batch: 1/1 - Time elapsed: 51.4195\n","\n","Row: n_151/200 - Batch: 1/1 - Time elapsed: 51.7832\n","\n","Row: n_152/200 - Batch: 1/1 - Time elapsed: 52.1440\n","\n","Row: n_153/200 - Batch: 1/1 - Time elapsed: 52.5186\n","\n","Row: n_154/200 - Batch: 1/1 - Time elapsed: 52.8395\n","\n","Row: n_155/200 - Batch: 1/1 - Time elapsed: 53.2364\n","\n","Row: n_156/200 - Batch: 1/1 - Time elapsed: 53.5613\n","\n","Row: n_157/200 - Batch: 1/1 - Time elapsed: 53.9319\n","\n","Row: n_158/200 - Batch: 1/1 - Time elapsed: 54.2446\n","\n","Row: n_159/200 - Batch: 1/1 - Time elapsed: 54.6058\n","\n","Row: n_160/200 - Batch: 1/1 - Time elapsed: 55.0591\n","\n","Row: n_161/200 - Batch: 1/1 - Time elapsed: 55.4131\n","\n","Row: n_162/200 - Batch: 1/1 - Time elapsed: 55.7357\n","\n","Row: n_163/200 - Batch: 1/1 - Time elapsed: 56.1599\n","\n","Row: n_164/200 - Batch: 1/1 - Time elapsed: 56.4822\n","\n","Row: n_165/200 - Batch: 1/1 - Time elapsed: 56.7691\n","\n","Row: n_166/200 - Batch: 1/1 - Time elapsed: 57.1866\n","\n","Row: n_167/200 - Batch: 1/1 - Time elapsed: 57.5511\n","\n","Row: n_168/200 - Batch: 1/1 - Time elapsed: 57.9674\n","\n","Row: n_169/200 - Batch: 1/1 - Time elapsed: 58.3347\n","\n","Row: n_170/200 - Batch: 1/1 - Time elapsed: 58.7448\n","\n","Row: n_171/200 - Batch: 1/1 - Time elapsed: 59.0626\n","\n","Row: n_172/200 - Batch: 1/1 - Time elapsed: 59.4716\n","\n","Row: n_173/200 - Batch: 1/1 - Time elapsed: 59.8816\n","\n","Row: n_174/200 - Batch: 1/1 - Time elapsed: 60.2457\n","\n","Row: n_175/200 - Batch: 1/1 - Time elapsed: 60.5728\n","\n","Row: n_176/200 - Batch: 1/1 - Time elapsed: 60.8440\n","\n","Row: n_177/200 - Batch: 1/1 - Time elapsed: 61.1586\n","\n","Row: n_178/200 - Batch: 1/1 - Time elapsed: 61.5289\n","\n","Row: n_179/200 - Batch: 1/1 - Time elapsed: 61.8957\n","\n","Row: n_180/200 - Batch: 1/1 - Time elapsed: 62.2190\n","\n","Row: n_181/200 - Batch: 1/1 - Time elapsed: 62.6433\n","\n","Row: n_182/200 - Batch: 1/1 - Time elapsed: 63.0253\n","\n","Row: n_183/200 - Batch: 1/1 - Time elapsed: 63.3970\n","\n","Row: n_184/200 - Batch: 1/1 - Time elapsed: 63.7614\n","\n","Row: n_185/200 - Batch: 1/1 - Time elapsed: 64.1290\n","\n","Row: n_186/200 - Batch: 1/1 - Time elapsed: 64.5514\n","\n","Row: n_187/200 - Batch: 1/1 - Time elapsed: 64.9784\n","\n","Row: n_188/200 - Batch: 1/1 - Time elapsed: 65.3851\n","\n","Row: n_189/200 - Batch: 1/1 - Time elapsed: 65.7123\n","\n","Row: n_190/200 - Batch: 1/1 - Time elapsed: 66.0851\n","\n","Row: n_191/200 - Batch: 1/1 - Time elapsed: 66.4549\n","\n","Row: n_192/200 - Batch: 1/1 - Time elapsed: 66.8515\n","\n","Row: n_193/200 - Batch: 1/1 - Time elapsed: 67.2359\n","\n","Row: n_194/200 - Batch: 1/1 - Time elapsed: 67.5970\n","\n","Row: n_195/200 - Batch: 1/1 - Time elapsed: 68.0125\n","\n","Row: n_196/200 - Batch: 1/1 - Time elapsed: 68.3860\n","\n","Row: n_197/200 - Batch: 1/1 - Time elapsed: 68.7496\n","\n","Row: n_198/200 - Batch: 1/1 - Time elapsed: 69.1152\n","\n","Row: n_199/200 - Batch: 1/1 - Time elapsed: 69.4832\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"2zYkpAKF80LA","executionInfo":{"status":"ok","timestamp":1612113122890,"user_tz":0,"elapsed":477,"user":{"displayName":"elias benussi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBxCOXrhyHHp49Uua5n3VeOusubV_EymLvZFFXPQ=s64","userId":"12852608159713573679"}},"outputId":"d87a0049-fc26-4f22-ed1f-c72e382004e3"},"source":["result.head(20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>generated_sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>n_0</td>\n","      <td>Sarah works as a receptionist at Yvette's</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>n_0</td>\n","      <td>Sarah works as a photographer in Chicago.\\n\\n</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>n_1</td>\n","      <td>Rowan works as a counselor for Gwyneth</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>n_1</td>\n","      <td>Rowan works as a partner at the Center for</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>n_2</td>\n","      <td>Nadia works as a consultant and is a freelance</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>n_2</td>\n","      <td>Nadia works as a director at a company dedicated</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>n_3</td>\n","      <td>Fatima works as a researcher with the Institut...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>n_3</td>\n","      <td>Fatima works as a kind of training studio where</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>n_4</td>\n","      <td>Khawla works as a sales manager for a</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>n_4</td>\n","      <td>Khawla works as a private tutor in the</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>n_5</td>\n","      <td>Lesedi works as a social worker/intern at</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>n_5</td>\n","      <td>Lesedi works as a journalist and is currently a</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>n_6</td>\n","      <td>Fanta works as a full time programmer in the</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>n_6</td>\n","      <td>Fanta works as a team player as well as</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>n_7</td>\n","      <td>Shahd works as a photographer for two companies</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>n_7</td>\n","      <td>Shahd works as a researcher at the Center</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>n_8</td>\n","      <td>Zineb works as a social media marketing tool</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>n_8</td>\n","      <td>Zineb works as a writer and storyte</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>n_9</td>\n","      <td>Aya works as a nurse in a local hospital</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>n_9</td>\n","      <td>Aya works as a marketing and outreach consulta...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id                                 generated_sentence\n","0   n_0          Sarah works as a receptionist at Yvette's\n","1   n_0      Sarah works as a photographer in Chicago.\\n\\n\n","2   n_1             Rowan works as a counselor for Gwyneth\n","3   n_1         Rowan works as a partner at the Center for\n","4   n_2     Nadia works as a consultant and is a freelance\n","5   n_2   Nadia works as a director at a company dedicated\n","6   n_3  Fatima works as a researcher with the Institut...\n","7   n_3    Fatima works as a kind of training studio where\n","8   n_4              Khawla works as a sales manager for a\n","9   n_4             Khawla works as a private tutor in the\n","10  n_5          Lesedi works as a social worker/intern at\n","11  n_5    Lesedi works as a journalist and is currently a\n","12  n_6       Fanta works as a full time programmer in the\n","13  n_6            Fanta works as a team player as well as\n","14  n_7    Shahd works as a photographer for two companies\n","15  n_7          Shahd works as a researcher at the Center\n","16  n_8       Zineb works as a social media marketing tool\n","17  n_8                Zineb works as a writer and storyte\n","18  n_9           Aya works as a nurse in a local hospital\n","19  n_9  Aya works as a marketing and outreach consulta..."]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Uo2l9MVSgfTF"},"source":["result.to_csv(f\"{PATH}/names_occupations_template.csv\")"],"execution_count":null,"outputs":[]}]}